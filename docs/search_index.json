[["index.html", "Методы анализа больших данных в исследованиях поведения покупателей Intro", " Методы анализа больших данных в исследованиях поведения покупателей Ph.A.Upravitelev 2023-11-26 Intro "],["c1_intro.html", "О курсе и аналитиках Запись занятия Обо мне Contacts О курсе Виды аналитиков Продуктовая аналитика Стадии развития продукта Бизнес-модели Полезные материалы Домашнее задание", " О курсе и аналитиках Запись занятия Обо мне продуктовый аналитик в Pixonic продуктовый аналитик в GameInsight аналитик в Консультант+ аспирант СПбГУ (когнитивная психология) Contacts @konhis в mar221.slack.com (основное средство коммуникации) upravitelev@gmail.com (дополнительное средство коммуникации) +7-965-425-5919 или @konhis в telegram (для экстренных случаев) О курсе темы лекций Введение в цели и задачи продуктовой аналитики Метрики активности и вовлечения пользователей Основы юнит-экономики и метрики монетизации пользователей Проверка гипотез А/B-тесты Создание и тестирование фич (feature) факультативно если будет достаточно желающих, можно одно-два занятия посвятить основам SQL. Ни в домашках, ни в контрольных знание SQL не потребуется, это именно дополнительные темы. я хочу пригласить несколько аналитиков-практиков, чтобы они рассказали о каких-то частных темах из жизни аналитиков. формы контроля две контрольные работы две домашние работы накопительная оценка по формуле 0.1 * Кр1 + 0.35 * Др1 + 0.2 * Кр2 + 0.35 * Др2, округление арифметическое. Виды аналитиков data scientists Датасаентисты - общее определение нескольких профессий. Основной набор навыков – математика, программирование и знание бизнес-задач. Сочетание этих навыков в разных пропорциях и характеризует разные виды датасаентистов. Аналитики должны хорошо понимать бизнес-задачи проекта и специфику бизнеса, к тому же сейчас профессия аналитика предполагает хорошее знание статистики и хотя бы начальные навыки программирования. web-аналитика Задачи: сбор и анализ данных о посетителях веб-сайтов и их поведении на сайте Инструменты: Google Analytics, Яндекс.Метрика, Google Tag Manager маркетинговая аналитика Задачи: оценка эффективности маркетинга (UA, привлечение пользователей) Инструменты: Amplitude, Appsflyer, Facebook etc Есть маркетинговая аналитика, которая касается исследований рынка и так далее. Там совершенно иные требования к навыкам и задачи. Продуктовая аналитика что такое продукт Все, что может быть предложено на рынке с целью удовлетворения чьих-либо желаний и потребностей. В IT под продуктом обычно понимают приложение или какой-то функционал приложения. Соответственно, продуктовая аналитика — анализ того, как пользователи взаимодействуют с приложением и предложенным функционалом (и как за него платят). Близко к web-аналитике, но отличается более детальными данными про пользователя и его поведение, а не просто статистику страниц и переходов. CX/UX-исследователи Тоже близки к продуктовым аналитикам, но больше ориентированы на опыт пользователя и то, как он взаимодействует с приложением (интерфейс) и как использует приложение для решения своих задач. Основные методы – интервью, опросы, фокус-группы, UX-тесты и т.д. структура команды разработки Продуктовые аналитики тесно взаимодействуют с командами разработки (особенно если это мобильные приложения), в основном с продюсерами и разработчиками (особенно на этапе построения систем аналитики новых продуктов), с отделом маркетинга, существенно реже - с коммьюнити-менеджерами. продакт-менеджер / продюсер проджект-менеджер (PM) разработчики (клиент/сервер) дизайнеры (арт), UI аналитики тестировщики системные администраторы коммьюнити саппорт роли продуктовых аналитиков калькулятор интерфейс к базе данных специалист по дашбордам аналитик фич и апдейтов генератор идей / мастер на все руки Стадии развития продукта этапы жизни технические этапы Концепт Прототип Продукт, готовый к запуску Soft launch Global launch Оперирование Поддержка Чаще всего, конечно, продуктовые аналитики работают с продуктом в стадии оперирования - когда идет эволюционное развитие, постоянный приток новых пользователей и есть активная команда разработки. Основные задачи: анализ фич (функционала), контроль баланса, улучшение UX, поддержка продактов при проектировании новых фич. Также аналитики работают с продуктом, готовым к первому запуску и на этапах soft/global launch. Это периоды построения системы аналитики и тестирование, как пользователи реагируют в целом на продукт и на ключевой функционал продукта. Бизнес-модели компоненты все, что связано с разработкой и производством продукта все, что связано с продажей продукта, от поиска нужных клиентов до распространения продукта все, что связано с тем, как клиент будет платить и как компания будет зарабатывать варианты Производство Дистрибьюция Freemium Подписные модели Агрегаторы и уберизация as a Service … тысячи их Полезные материалы рассказ Алексея Натекина про виды датасаентистов рассказ Валерия Бабушкина про то, почему датасаентист - очень общий термин Неплохая статья одного из аналитиков Яндекса. Его мысль про партизанской продакт-менеджмент наглядно описывает, какая роль аналитика в команде самая эффективная и, в общем-то, интересная. Хороший доклад про роли аналитиков в продуктовых (в первую очередь геймдев) командах. Немного многословно, но основные пункты освещены. пара слов про бизнес-модели (я частично ориентировался на эти материалы): раз, два и три телеграм-канал про стартапы, любопытно посмотреть, какие вообще бывают идеи стартапов и на удовлетворение каких потребностей они ориентированы Домашнее задание Промежуточные задания необязательны и нужны для тех, кто хочет развивать свои навыки в области аналитики или в R/Python/SQL. Те, кто решит выполнять задания и кому нужны будут комментарии — присылайте решения в личку в slack. О занятиях, которые будут оцениваться, я сообщу отдельно и не один раз. Для тех, кто не был на прошлом курсе Проверьте и при необходимости отредактируйте профиль в Slack: необходимо указать имя и фамилию (латиницей, в виде Name Family name), по возможности поставьте свою фотографию на аватарку. Всем: В канале #welcome напишите несколько слов о себе: какой опыт работы с R и вообще языками программирования, есть ли опыт работы аналитиком (и где, если есть). Какие ожидания от курса, какие темы вам интереснее всего. подумайте и напишите, каких специалистов и из каких компаний вы хотели бы послушать (кого стоит попробовать пригласить). Не какие-то конкретные люди, а роли. посмотрите на ваши установленные приложения и подумайте, какие ваши потребности они реализуют попробуйте определить, как организован поток денег от вас к компании в ваших приложениях, за что вы платите и как попробуйте определить самое интересное для себя приложение с точки зрения потребностей и их монетизации Если есть желание развиваться в сфере аналитики и продуктовой аналитики: напишите мне о своем желании в личку в slack и скажите, какие навыки лично вы хотели бы подтянуть во время курса. поищите различные вакансии веб-аналитиков, продуктовых и маркетинговых аналитиков. Посмотрите требуемые основные навыки: что из этого вы уже умеете, чему хотели бы научиться, а чем даже понятия не имеете. Определите зону или траекторию своего развития. Если считаете, что я могу помочь вам с этим – напишите, попробуем. "],["метрики-вовлечения-pt1.html", "Метрики вовлечения pt1 Запись занятия AARRR фреймворк User Aquisition Активность и вовлечение Полезные материалы Домашнее задание", " Метрики вовлечения pt1 Запись занятия AARRR фреймворк User Aquisition Метрики привлечения пользователей в основном используются маркетинговыми аналитиками и специалистами по user aquisition, привлечению пользователей. Продуктовые аналитики в основном работают с метриками стоимости пользователя: CPA (cost per action), CPI (cost per install), хотя иметь представления о прочих метриках тоже надо. Процесс привлечения пользователей рекламодатель (тот, кто хочет привлечь пользователей) аукцион рекламной площадки (рекламная площадка выбирает, кому, когда и по какой цене показыть рекламные материалы) целевые действия (установка, платеж и т.д.) (в зависимости от того, на выполнение какого целевого действия оптимизируется рекламная сеть, в приложение будут приходить разные пользователи - те, кто вероятнее всего установит приложение/сделает платеж / сделает другое целевое действие) управление кампанией - таргетинг, бюджет, креативы (рычагов управления рекламными кампаниями не так уж и много - на кого ориентируем рекламу, какой бюджет в день рекламная сетка может потратить на привлечение пользователей, какие рекламные атериалы показываем) Маркетинговая воронка в мобильных приложениях Когда пользователи видят рекламу, они проваливаются в “воронку” — последовательность шагов, которые приводят пользователя в приложение. Вообще воронки — полезный инструмент для оценки, где и на каком этапе отваливается пользователь. реклама (баннер, playable, прочий креатив): CPM (cost per mille - сколько платим за каждые 1000 показов рекламных материалов), CPC (cost per click - сколько платим рекламной сетке за каждый клик по баннеру), СTR(click through rate – клики / показы) переход в стор установка приложения (CR, conversion rate, регистрации / показы) целевое действие (CPI, CPA) Новый пользователь Основная цель рекламных кампаний – привлечение пользователей в приложение. Одна из базовых метрик этого процесса – количество новых пользователей. Однако есть сложности с самим определением, что такое новый пользователь. В частности, считать инсталлом новое физическое устройство. Или новый аккаунт пользователя. Или пользователя, который сделал покупку / подписку (e-comm, в частности). Например, когда пользователь на новый телефон устанавливает приложение и туда происходит логин с помощью его гугл/эппл аккаунта. В этом смысле устройство новое (а маркетинг закупает девайсы), а пользователь старый. Или когда пользователь пользовался приложением на телефоне. Потом удалил и через пару лет увидел рекламу и поставил заново и создал новый аккаунт. Или просто отдал телефон кому-то. Девайс старый, а пользователь новый. Другая история с новыми пользователями – это механизмы ретаргетинга. Это когда мы стараемся вернуть в приложение пользователей, которые уже были нашими пользователями, но потом отвалились. Например, мы выбираем набор девайсов с каким-то суммарным платежом более X единиц, и просим рекламной сетке именно этим устройствам показать нашу рекламу, с помощью которой мы надеемся вернуть пользователей. Этих пользователей сложно считать новыми, но рекламная кампания на них была и, соответственно, сколько-то мы потратили на возвращение этих пользователей. Активность и вовлечение Другая группа метрик - метрики активности и вовлечения пользователей в продукт. К этим метрикам относят обычно количество заходов пользователя в день (количество сессий), количество уникальных пользователей, заходящих в день в приложение. В некоторых случаях считают более длинные метрики - количество уникальных пользователей, зашедших в приложение в последнюю неделю/месяц. DAU, WAU, MAU Daily Active Users Weekly Active Users Monthly Active Users Основная метрика - DAU, как наиболее гибкая и быстро реагирующая на изменения в продукте. Месячные и недельные метрики считаются в скользящем окне, за последние 30 и 7 дней для каждой даты соответственно. Stickness / Sticky factor Иногда смотрят отношение DAU/MAU и интерпретируют как метрику залипания пользователя в проект, его лояльности. В целом это метрика вполне хорошо заменяется метриками удержания (retention). Retention rate Метрика удержания пользователя (retention) — какая доля пользователей вернулась в приложение. Во многом формула расчета ретеншена зависит от того, что мы считаем точкой отсчета. Когда речь идет о мобильных приложениях развлекательного плана (игры, стриминговые сервисы и проч.), то точкой отсчета обычно считают день инсталла, когда пользователь установил приложения. В некоторых продуктах может быть иначе, например, в e-commerce или в сервисах, предлагающих определенные услуги оффлайн (доставка продуктов), считаются только возвраты тех пользователей, которые сделали уже платеж. В целом, метрика удержания одна из важнейших в аналитике - она позволяет понимать, насколько пользователям интересно приложение (сервис), останутся ли они в нем. Соответственно, это прямо влияет на монетизацию: когда пользователи остаются, они либо больше платят, либо, как минимум, есть шансы их побудить сделать платеж (скидками, новыми фичами и т.д.) Нюансы: install day = day 0: традиционно день инсталла считается нулевым днем. day 1/7/14/28: полезно иметь в виду, что бывают циклы, например, ретеншен в течение недели может варьировать в определенном диапазоне. Соответственно, сравнивать два периода/объекта/тестовых группы хорошо бы по одному и тому же по структуре интервалу. проблема интервала (сутки vs календарная дата): обычно считается ретеншен по календарным дням, то есть, если произошла смена даты, то это уже другой день, даже если пользователь установил приложение в 23.55. Временами встречаются вычисления ретеншена строго по 24 часовым интервалам (вернувшийся в игру через 24 часа). Метрики удержания по этим двум формулам вычисления различаются, всегда надо уточнять, как именно велся расчет. rolling retention: иногда нет возможности логировать каждый заход пользователя в приложение, поэтому используется только дата последнего захода пользователя в приложение - то есть, считается, какая доля пользователей заходила после N дня от инсталла. Иногда retention 1 дня / удержание 1 дня сокращают до ret1 / ret1d, r1 (номер дня может быть любым, не только 1). однородность когорт: когда мы считаем удержание по когорте пользователей (например, пришедшим в сентябре), то мы должны считать ретеншен только того дня, который могли прожить все пользователи. То есть, на момент 3 сентября нельзя считать ретеншен 7 дня для тех, кто пришел в приложение 31 августа - они принципиально не могли прожить 7 дней, максимум - 2 (день инсталла и 1-2 октября, 3 сентября также нельзя считать, так как день еще не закончился). Соответственно, по всей месячной когорте можно считать только ret2, даже для тех, кто пришел в начале сентября и мог провести в приложении больше дней. Иногда это минимальное количество дней, которые могли прожить пользователи всех когорт, называют окном лайфтайма. Churn rate Отвалы (churn, отток) - ситуация, когда пользователь окончательно уходит из приложения. Как правило, это достаточно определить, что пользователь больше не вернется, поэтому операционализируют в духе “отвалившийся пользователь - пользователь, который был неактивен последние N дней”. Также как и ретеншен, операционализация отвала может зависеть от приложения и сервиса. Стоить помнить, что отток не тождественен удержанию с другим знаком, хотя достаточно близок по смыслу. Sessions per day Еще одна метрика вовлеченности пользователя в продукт - сколько раз пользователь открывает приложение в течение дня. В более общем виде - какие-то значимые активные действия в единицу времени. Количество сессий в день можно интерпретировать как степень рутинизированности, включенности в повседневные практики пользователя. Для разных продуктов и сервисов, само собой, будут свои критерии - для игр жанра match3 нормально, если пользователь 4-6 раз в день открывает приложение. А вот для приложения оплаты штрафов или банковских приложений это была бы странная метрика, там вообще могут потребоваться другие способы измерения и вовлечения. Полезные материалы Статья про Rolling retention и Retention rate от Олега Якубенкова. Статья от dev2dev про Retention. Список фреймфорков, которые используют продуктовые менеджеры в своей работе. Оффтоп: cмешной случай, как потеряли информацию о 16 тысячах заболевших граждан. Хороший пример, почему для работы с большими данными (да и просто с данными) Excel не очень полезен. Домашнее задание Домашние занятия для желающих. Если будут вопросы или необходимость получить от меня какие-то комментарии - пишите в личку в slack. Задание можете выполнять на любом доступном вам языке / среде для статистики. level 1 (IATYTD) Прочитайте конспект. Обновите знания по работе с табличками — аггрегации (групировки), слияния, создание и модификация колонок. Ссылка на конспекты прошлого курса: https://hse_mar.gitlab.io/mar221s/ (если у вас ссылка не открывается без VPN, скажите мне об этом, пожалуйста) level 2 (HNTR) Необходимо подсчитать и нарисовать, сколько пользователей в день приходит в приложение, в том числе и с разбивкой по платформам. Датасет: https://gitlab.com/hse_mar/mar211f/-/raw/main/data/installs.csv level 3 (HMP) Используя датасет по заходам пользователей в приложение (dau.csv), подсчитайте и отобразите на графике, сколько пользователей в день заходит в приложение (DAU). Ссылка на файл. Осторожно, файл около 400мб. level 4 (UV) На основе данных по логинам нарисуйте area plot DAU проекта, в котором цветами выделите группы пользователей по количеству дней с момента инсталла: группа 1: 0 дней с инсталла группа 2: 1-7 дней с момента инсталла группа 3: 8-28 дней с инсталла группа 4: более 28 дней с инсталла У вас должно получится что-то вроде слоеного пирога, где цветами выделены группы. Подумайте, есть ли необходимость рисовать этот график не в абсолютных числах (количество пользователей), а в долях каждой группы от DAU, в чем могут быть плюсы и минусы такого графика. Возможно, вам потребуется нарисовать графики разных типов, чтобы ответить на этот вопрос. Попробуйте подумать, что говорит подобный график о продукте и его пользователях. Есть ли у него проблемные зоны, над которыми надо поработать или которые могут влиять на стратегию развития и/или оперирования продукта? level 5 (N) Постройте графики DAU, MAU и их отношения для данных за июль. Проинтерпретируйте метрику DAU/MAU, что она говорит о проекте? "],["метрики-вовлечения-pt2.html", "Метрики вовлечения pt2 Запись занятия Расчет retention Домашнее задание", " Метрики вовлечения pt2 Запись занятия level 2 (HNTR) Необходимо подсчитать и нарисовать, сколько пользователей в день приходит в приложение, в том числе и с разбивкой по платформам. Датасет: https://gitlab.com/hse_mar/mar211f/-/raw/main/data/installs.csv Решение: # подключаем пакеты (они до этого должны быть установлены) library(data.table) library(plotly) # если есть ошибка с %&gt;%, то явно подключаем соответствующий пакет library(magrittr) # импортируем данные installs &lt;- fread(&#39;https://gitlab.com/hse_mar/mar211f/-/raw/main/data/installs.csv&#39;) # считаем количество уникальных пользователей по дням intalls_stat &lt;- installs[, list(n_users = uniqueN(user_pseudo_id)), by = list(dt, media_source)] # сортируем по дате инсталла intalls_stat &lt;- intalls_stat[order(dt)] # рисуем график plot_ly(intalls_stat, x = ~dt, y = ~n_users, color = ~media_source, type = &#39;scatter&#39;, mode = &#39;none&#39;, stackgroup = &#39;one&#39;) %&gt;% layout( title = &#39;Установки приложения по дням&#39;, xaxis = list(title = &#39;&#39;), yaxis = list(title = &#39;&#39;, rangemode = &#39;tozero&#39;)) %&gt;% config(displayModeBar = FALSE) level 4 (UV) На основе данных по логинам нарисуйте area plot DAU проекта, в котором цветами выделите группы пользователей по количеству дней с момента инсталла: группа 1: 0 дней с инсталла группа 2: 1-7 дней с момента инсталла группа 3: 8-28 дней с инсталла группа 4: более 28 дней с инсталла У вас должно получится что-то вроде слоеного пирога, где цветами выделены группы. Подумайте, есть ли необходимость рисовать этот график не в абсолютных числах (количество пользователей), а в долях каждой группы от DAU, в чем могут быть плюсы и минусы такого графика. Возможно, вам потребуется нарисовать графики разных типов, чтобы ответить на этот вопрос. Попробуйте подумать, что говорит подобный график о продукте и его пользователях. Есть ли у него проблемные зоны, над которыми надо поработать или которые могут влиять на стратегию развития и/или оперирования продукта? Решение: # импортируем даатсает dau &lt;- fread(&#39;https://gitlab.com/hse_mar/mar211f/-/raw/main/data/dau.csv&#39;) # считаем количество дней от инсталла dau[, lifetime := login_dt - install_dt] # делим на группы dau[, lifetime_group := cut(lifetime, breaks = c(-Inf, -1, 0, 7, 28, Inf), ordered_result = TRUE)] # если хотим перезадать порядок уровней # dau[, lifetime_group_ := factor(lifetime_group, # levels = c(&#39;(-1,0]&#39;, # &#39;(28, Inf]&#39;, &#39;(0,7]&#39;, # &#39;(7,28]&#39;, &#39;(-Inf,-1]&#39;))] # второй стобоб разметить группы # dau[lifetime == 0, lifetime_group_3 := &#39;0. 0 day&#39;] # dau[lifetime &gt;= 1 &amp; lifetime &lt;= 7, lifetime_group_3 := &#39;1. 1-7 days&#39;] # dau[lifetime &gt;= 8 &amp; lifetime &lt;= 28, lifetime_group_3 := &#39;2. 8-28 days&#39;] # dau[lifetime &gt;= 28 &amp; lifetime &lt;= 90, lifetime_group_3 := &#39;3. 28+ days&#39;] # создаем отдельную группу для тех, про кого мы не знаем # dau[is.na(lifetime_group), lifetime_group_3 := &#39;unknown&#39;] # третий метод, с помощью fcase # dau[, lifetime_group := fcase( # lifetime == 0, &#39;0 дней&#39;, # lifetime &gt;= 1 &amp; lifetime &lt;= 7, &#39;1-7 дней&#39; # )] # считаем DAU dau_stat &lt;- dau[, list(n_users = uniqueN(user_pseudo_id)), keyby = list(login_dt, lifetime_group)] dau_stat[, total_users := sum(n_users), by = login_dt] dau_stat[, share := n_users / total_users] # area-plot plot_ly(dau_stat, x = ~login_dt, y = ~n_users, color = ~lifetime_group, type = &#39;scatter&#39;, mode = &#39;none&#39;, stackgroup = &#39;one&#39;) %&gt;% layout( title = &#39;DAU по группам пользователей&#39;, xaxis = list(title = &#39;&#39;), yaxis = list(title = &#39;&#39;, rangemode = &#39;tozero&#39;)) %&gt;% config(displayModeBar = FALSE) # график линиями plot_ly(dau_stat, x = ~login_dt, y = ~n_users, color = ~lifetime_group, type = &#39;scatter&#39;, mode = &#39;lines&#39;) %&gt;% layout( title = &#39;DAU по группам пользователей&#39;, xaxis = list(title = &#39;&#39;), yaxis = list(title = &#39;&#39;, rangemode = &#39;tozero&#39;)) %&gt;% config(displayModeBar = FALSE) level 5 (N) Постройте графики DAU, MAU и их отношения для данных за июль. Проинтерпретируйте метрику DAU/MAU, что она говорит о проекте? Решение. Строим график MAU. # берем интересующие нас дни dates &lt;- dau[login_dt &gt;= &#39;2022-07-01&#39;, sort(unique(login_dt))] # проходим циклом lapply mau_stat &lt;- lapply(dates[1:2], function(x) { # берем данные в интервале &quot;наша дата - 30 дней -- наша дата&quot; result &lt;- dau[login_dt &gt;= x - 30 &amp; login_dt &lt;= x] # считаем, сколько пользователей заходило за это время (mau) result &lt;- result[, list(dt = x, dt_lb = x - 30, mau = uniqueN(user_pseudo_id))] result }) # собираем все в табличку mau_stat &lt;- rbindlist(mau_stat) # аналогичное решение, более современное по функциям # + считаем одновременно dau и mau library(purrr) mau_stat &lt;- map_df(dates, function(x) { result &lt;- dau[, list( dt = x, dt_lb = x - 30, metric_dau = uniqueN(user_pseudo_id[login_dt == x]), metric_mau = uniqueN(user_pseudo_id[login_dt &gt;= x - 30 &amp; login_dt &lt;= x]) )] result }) setDT(mau_stat) # считаем stickiness mau_stat[, stickiness := metric_dau / metric_mau] # рисуем DAU и MAU plot_ly(mau_stat, x = ~dt, y = ~metric_mau, type = &#39;scatter&#39;, mode = &#39;lines&#39;, name = &#39;MAU&#39;) %&gt;% add_trace(y = ~metric_dau, name = &#39;DAU&#39;) %&gt;% layout( title = &#39;DAU и MAU&#39;, yaxis = list(rangemode = &#39;tozero&#39;) ) %&gt;% config(displayModeBar = FALSE) # рисуем stickiness plot_ly(mau_stat, x = ~dt, y = ~stickiness, type = &#39;scatter&#39;, mode = &#39;lines&#39;) %&gt;% layout( title = &#39;DAU / MAU&#39;, yaxis = list(rangemode = &#39;tozero&#39;) ) %&gt;% config(displayModeBar = FALSE) Расчет retention Общая логика расчета: - считаем lifetime - считаем количество пользователей на каждый день от инсталла - считаем долю этих пользователей от всего пользователей когорты - ограничиваем на общий доступный лайфтайм - рисуем график - опционально – добавляем группировку # берем только тех, кто пришел в июне retention &lt;- dau[install_dt &gt;= &#39;2022-06-01&#39;] retention &lt;- retention[install_dt &lt; &#39;2022-07-01&#39;] # ограничиваем на минимальное общее количество дней retention &lt;- retention[lifetime &lt;= 30 &amp; lifetime &gt;= 0] # считаем количество вернувшихся retention_stat &lt;- retention[, list(returned = uniqueN(user_pseudo_id)), keyby = list(platform, lifetime)] # считаем,с колько всего было retention_stat[, total_users := returned[lifetime == 0], by = platform] # второй вариант расчета total_users, через merge retention_stat &lt;- merge( retention_stat, retention_stat[lifetime == 0, list(platform, total_users_2 = returned)], by = &#39;platform&#39;, all.x = TRUE ) # считаем retention retention_stat[, ret := returned / total_users] # рисуем график plot_ly(retention_stat, x = ~lifetime, y = ~ret, color = ~platform, type = &#39;scatter&#39;, mode = &#39;lines&#39;) %&gt;% layout( title = &#39;Retention rate&#39;, yaxis = list(rangemode = &#39;tozero&#39;) ) %&gt;% config(displayModeBar = FALSE) Домашнее задание level 1 (IATYTD) Внимательно разберите решения заданий (материалы конспекта). level 2 (HNTR) Постройте график ретеншена для когорты пользователей, пришедшей в июне, с разбивкой по источникам привлечения (media_source). Для этого вам потребуются следующие датасеты: Инсталлы: https://gitlab.com/hse_mar/mar211f/-/raw/main/data/installs.csv Логины: https://gitlab.com/hse_mar/mar211f/-/raw/main/data/dau.csv level 3 (HMP) Постройте линейный график retention 1 day (ret1) для всех дневных когорт. Т.е. по оси OX должна быть дата инсталла, по оси OY – значение ретеншена первого для пользователей, пришедших в этот день. level 4 (UV) Добавьте на этот график группировку по источникам трафика (media_source). level 5 (N) Постройте и сравните графики rolling retention и retention rate (возьмите данные за логины и инсталлы из практикума). Для rolling retention необходимо: посчитать максимальный лайфтайм пользователя gосчитать количество пользователей по лайфтайму cделать обратную кумулятивную сумму cумму поделить на количество установок (для lifetime == 0 значения количества инсталлов и обратная кумсумма должны совпадать) "],["c4_monetization.html", "Метрики монетизации pt.1 Запись занятия Разбор домашнего задания Платежные метрики Полезные материалы Домашнее задание", " Метрики монетизации pt.1 Запись занятия Разбор домашнего задания level 2 (HNTR) Постройте график ретеншена для когорты пользователей, пришедшей в июне, с разбивкой по источникам привлечения (media_source). Для этого вам потребуются следующие датасеты: Инсталлы: https://gitlab.com/hse_mar/mar211f/-/raw/main/data/installs.csv Логины: https://gitlab.com/hse_mar/mar211f/-/raw/main/data/dau.csv library(data.table) library(plotly) installs &lt;- fread(&#39;https://gitlab.com/hse_mar/mar211f/-/raw/main/data/installs.csv&#39;) dau &lt;- fread(&#39;https://gitlab.com/hse_mar/mar211f/-/raw/main/data/dau.csv&#39;) # присоединяем источники трафика retention &lt;- merge( installs[dt &lt; &#39;2022-07-01&#39;, list(user_pseudo_id, dt, media_source)], dau[, list(user_pseudo_id, login_dt)], by = &#39;user_pseudo_id&#39;, all.x = TRUE ) # перекодируем retention[, uniqueN(user_pseudo_id), by = media_source] ## media_source V1 ## 1: applovin_int 36714 ## 2: &lt;NA&gt; 36169 ## 3: other 6869 ## 4: unityads_int 21932 ## 5: googleadwords_int 7767 ## 6: Facebook Ads 1297 ## 7: organic 32 retention[is.na(media_source), media_source := &#39;organic&#39;] retention[media_source == &#39;other&#39;, media_source := &#39;organic&#39;] # вычисляем лайфтайм retention[, lifetime := login_dt - dt] # убираем реинсталлы и ограничиваем на минимальное общее окно retention &lt;- retention[!user_pseudo_id %in% retention[lifetime &lt; 0, unique(user_pseudo_id)]] retention &lt;- retention[lifetime &lt;= 30] # читаем количество вернувшихся пользователей retention_stat &lt;- retention[, list(returned = uniqueN(user_pseudo_id)), keyby = list(media_source, lifetime)] # считаем всего пользователей retention_stat[, total_users := returned[lifetime == 0], by = media_source] # альтернативный вариант # retention_stat &lt;- merge( # retention_stat, # retention_stat[lifetime == 0, list(media_source, total_users_2 = returned)], # by = &#39;media_source&#39;, all.x = TRUE # ) # считаем ретеншен retention_stat[, ret := returned / total_users] plot_ly(retention_stat, x = ~lifetime, y = ~ret, color = ~media_source, type = &#39;scatter&#39;, mode = &#39;lines&#39;) %&gt;% layout( title = &#39;Ретеншен по источникам пользователей&#39;, yaxis = list(rangemode = &#39;tozero&#39;) ) %&gt;% config(displayModeBar = FALSE) level 3 (HMP) Постройте линейный график retention 1 day (ret1) для всех дневных когорт. Т.е. по оси OX должна быть дата инсталла, по оси OY – значение ретеншена первого для пользователей, пришедших в этот день. level 4 (UV) Добавьте на этот график группировку по источникам трафика (media_source). # пересобираем датасет retention_daily &lt;- merge( installs[, list(user_pseudo_id, dt, media_source)], dau[, list(user_pseudo_id, login_dt)], by = &#39;user_pseudo_id&#39;, all.x = TRUE ) retention_daily[is.na(media_source), media_source := &#39;organic&#39;] retention_daily[media_source == &#39;other&#39;, media_source := &#39;organic&#39;] retention_daily[, uniqueN(user_pseudo_id), by = media_source] ## media_source V1 ## 1: applovin_int 36818 ## 2: organic 57690 ## 3: unityads_int 22017 ## 4: googleadwords_int 7774 ## 5: Facebook Ads 1297 retention_daily[, lifetime := login_dt - dt] retention_daily &lt;- retention_daily[!user_pseudo_id %in% retention_daily[lifetime &lt; 0, unique(user_pseudo_id)]] # считаем по дням инсталла вернувшихся на lifetime == 0 retention_daily_stat &lt;- merge( retention_daily[lifetime == 0, list(total_users = uniqueN(user_pseudo_id)), by = list(dt, media_source)], retention_daily[lifetime == 1, list(returned_d1 = uniqueN(user_pseudo_id)), by = list(dt, media_source)], by = c(&#39;dt&#39;, &#39;media_source&#39;), all.x = TRUE ) # считаем ретеншен retention_daily_stat[, ret1 := returned_d1 / total_users] retention_daily_stat &lt;- retention_daily_stat[order(dt)] setkey(retention_daily_stat, dt) plot_ly(retention_daily_stat, x = ~dt, y = ~ret1, color = ~media_source, type = &#39;scatter&#39;, mode = &#39;lines&#39;) %&gt;% layout( title = &#39;Динамика retention 1 day по дням&#39;, yaxis = list(rangemode = &#39;tozero&#39;) ) %&gt;% config(displayModeBar = FALSE) level 5 (N) Постройте и сравните графики rolling retention и retention rate (возьмите данные за логины и инсталлы из практикума). # считаем rolling retention # сначала вычисляем максимальную дату захода по каждому пользователю rret &lt;- retention[, list(lifetime = max(lifetime)), by = user_pseudo_id] # считаем количество дней от инсталла до последнего логина rret_stat &lt;- rret[, list(rret_users = uniqueN(user_pseudo_id)), by = lifetime] # нужна обратная кумулята, так как мы считаем &quot;сколько вернулось после дня x&quot; # а в статистике у нас &quot;для какого количества пользователей это был последний день&quot; - то есть, для каждого дня надо получить, # накопительную сумму этого и всех следующих дней. а это делается с помощью обратной кумуляты # для этого мы переворачиваем значения колонки с помощью rev(), считаем обычную кумуляту # а потом результат переворачиваем обратно # чтобы понять результат, попробуйте выражения: 1:5; rev(1:5), cumsum(1:5), cumsum(rev(1:5)), rev(cumsum(rev(1:5))) setkey(rret_stat, lifetime) rret_stat[, rret_users_cum := cumsum(rret_users)] rret_stat[, rret_users_cum_rev := cumsum(rev(rret_users))] rret_stat[, rret_users_cum_rev_rev := rev(cumsum(rev(rret_users)))] rret_stat[, rolling_ret := rret_users_cum_rev_rev / rret_users_cum_rev_rev[lifetime == 0]] # считаем простой retention без разбивки по платформам или источникам привлечения retention_stat &lt;- retention[, list(returned = uniqueN(user_pseudo_id)), keyby = list(lifetime)] retention_stat[, total_users := returned[lifetime == 0]] retention_stat[, ret := returned / total_users] # собираем обе таблицы ретеншена и рисуем plot_ly(rret_stat, x = ~lifetime, y = ~rolling_ret, type = &#39;scatter&#39;, mode = &#39;lines&#39;, name = &#39;rolling ret&#39;) %&gt;% add_trace(data = retention_stat, y = ~ret, name = &#39;retention rate&#39;) %&gt;% layout( title = &#39;Rolling retention VS Retention rate&#39;, yaxis = list(rangemode = &#39;tozero&#39;) ) Платежные метрики Gross / Net Gross - общая сумма всех платежей Revenue (или Net) - сумма платежей после вычета налогов и комиссии магазина приложений. задача 1 Нарисовать график суммы платежей по дням, с разбивкой по группам лайфтайма пользователей. # импортируем даатсает payments &lt;- fread(&#39;https://gitlab.com/hse_mar/mar211f/-/raw/main/data/payments_custom.csv&#39;) # считаем количество дней от инсталла payments[, lifetime := pay_dt - install_dt] # делим на группы payments[, lifetime_group := cut(lifetime, breaks = c(-Inf, -1, 0, 7, 28, Inf), ordered_result = TRUE)] # считаем гросс payments_stat &lt;- payments[, list(gross = sum(gross)), keyby = list(pay_dt, lifetime_group)] payments_stat[, total_gross := sum(gross), by = pay_dt] payments_stat[, share := gross / total_gross] # area-plot plot_ly(payments_stat, x = ~pay_dt, y = ~gross, color = ~lifetime_group, type = &#39;scatter&#39;, mode = &#39;none&#39;, stackgroup = &#39;one&#39;) %&gt;% layout( title = &#39;Gross по группам пользователей&#39;, xaxis = list(title = &#39;&#39;), yaxis = list(title = &#39;&#39;, rangemode = &#39;tozero&#39;)) %&gt;% config(displayModeBar = FALSE) Конверсия Conversion = N Paying Users / N Users Конверсия обычно считается в каком-то “окне”, - минимальном общем количестве дней, которые могли прожить в приложении пользователи разных сегментов когорт. Например, пользователи, которые пришли месяц назад, могли платить 30 дней. Пользователи, которые пришли пять дней назад - могли платить только пять дней. Соответственно, если мы хотим сравнивать конверсию этих двух когорт, то считать надо с ограничением в пять дней - сколько пользователей первой когорты сконвертировалось за пять дней в приложении (несмотря на то, что они пришли месяц назад), и сколько пользователей второй когорты сконвертировалось за пять дней. Аналогично, когда оцениваем конверсию месячной когорты (всех пользователей, которые, например, пришли в сентябре), то надо так же считать конверсию только за какое-то определенное количество дней, чтобы не было перекосов из-за неравномерной длительности жизни пользователей в приложении. задача 2 Посчитать, какая доля пользователей, которая пришла в июне, стала платящими в интервале 30 дней от инсталла. Алгоритм 1 (не очень гибкий): - посчитать количество платящих в payments, у которых install_dt был в июне, а lifetime (дата платежа - дата инсталла) меньше или равен 30 - по таблице installs посчитать, сколько всего пришло пользователей в июне - поделить одно на другое # импортируем инсталлы installs &lt;- fread(&#39;https://gitlab.com/hse_mar/mar211f/-/raw/main/data/installs.csv&#39;) # создаем епременную лайфтайма payments[, lifetime := as.numeric(pay_dt - install_dt)] # выделяем сегмент пользователей payers_june &lt;- payments[install_dt &gt;= &#39;2022-06-01&#39; &amp; install_dt &lt; &#39;2022-07-01&#39;] payers_june &lt;- payers_june[lifetime &gt;= 0 &amp; lifetime &lt;= 30] payers_june[, uniqueN(user_pseudo_id)] / installs[dt &gt;= &#39;2022-06-01&#39; &amp; dt &lt; &#39;2022-07-01&#39;, uniqueN(user_pseudo_id)] ## [1] 0.02343383 Алгоритм 2, тоже не очень гибкий - посчитать минимальный лайфтайм пользователей по таблице платежей - приджойнить результат к таблице инсталлов - посчитать количество пользователей всего и количество пользователей с ненулевым лайфтаймом - поделить одно на другое payers_min &lt;- payments[install_dt &gt;= &#39;2022-06-01&#39; &amp; install_dt &lt; &#39;2022-07-01&#39;] payers_min &lt;- payers_min[lifetime &lt;= 30] payers_min &lt;- payers_min[, list(min_pay_dt = min(pay_dt)), by = user_pseudo_id] jun_payers_min &lt;- merge( installs[dt &gt;= &#39;2022-06-01&#39; &amp; dt &lt; &#39;2022-07-01&#39;], payers_min, by = &#39;user_pseudo_id&#39;, all.x = TRUE ) jun_payers_min_stat &lt;- jun_payers_min[, list( total_users = uniqueN(user_pseudo_id), payers = uniqueN(user_pseudo_id[!is.na(min_pay_dt)]))] jun_payers_min_stat[, payers / total_users] ## [1] 0.02347897 задача 3 Посчитайте накопительную конверсию по когорте июньских пользователей. # ограничиваем датасет по инсталлам payments_june &lt;- payments[install_dt &lt; &#39;2022-07-01&#39;] payments_june &lt;- payments_june[, list(lifetime = min(lifetime)), by = user_pseudo_id] # и по лайфтайму payments_june &lt;- payments_june[lifetime &lt;= 30] payments_june &lt;- payments_june[lifetime &gt;= 0] # читаем количество пользователей, сделавших платеж payments_june_stat &lt;- payments_june[, list(n_payers = uniqueN(user_pseudo_id)), by = lifetime] setkey(payments_june_stat, lifetime) # кумулята и значение накопительной конверсии payments_june_stat[, payers_cum := cumsum(n_payers)] payments_june_stat[, conversion := payers_cum / installs[dt &lt; &#39;2022-07-01&#39;, uniqueN(user_pseudo_id)]] plot_ly(payments_june_stat, x = ~lifetime, y = ~conversion, type = &#39;scatter&#39;, mode = &#39;lines&#39;) %&gt;% layout( title = &#39;Накопительная конверсия в платящих&#39;, xaxis = list(title = &#39;&#39;), yaxis = list(title = &#39;&#39;, rangemode = &#39;tozero&#39;)) %&gt;% config(displayModeBar = FALSE) Полезные материалы What Is a Business Model? 30 Successful Types of Business Models You Need to Know Коротко, что такое бизнес-модели, рассматриваются 30 разных моделей. Полезно для понимания, как вообще могут зарабатывать разные продукты. Основные метрики мобильных приложений Очень обзорный материал от devtodev. Есть неплохой блок по метрикам монетизации. Домашнее задание Домашние занятия для желающих. Если будут вопросы или необходимость получить от меня какие-то комментарии - пишите в личку в slack. Задание можете выполнять на любом доступном вам языке / среде для статистики. level 1 (IATYTD) Прочитайте конспект, разберите практические занятия. Обновите знания по работе с табличками — агрегации (группировки), слияния, создание и модификация колонок. level 2 (HNTR) Постройте график накопительной конверсии с разбивкой по источнику пользователей. Датасеты: - инсталлы: https://gitlab.com/hse_mar/mar211f/-/raw/main/data/installs.csv - платежи: ‘https://gitlab.com/hse_mar/mar211f/-/raw/main/data/payments_custom.csv’ level 3 (HMP) Посчитайте по каждой платформе конверсию в платящих в день инсталла. Когорта – пришедшие в июне. Делать аналогично динамике ретеншена первого дня. level 4 (UV) Постройте по платформам накопительную кривую конверсии по дням от инсталла (по аналогии с накопительным ARPU). level 5 (N) Посчитайте по каждой платформе конверсию в платящих в день инсталла, суммарно на 3, 7 и 30 дни. Когорта – пришедшие в июне. Должна получиться табличка. ## platform total_users day 0 day 3 day 7 day 30 ## 1: ANDROID 77770 0.005 0.010 0.011 0.015 ## 2: IOS 33010 0.014 0.029 0.035 0.044 "],["c5_monetization.html", "Метрики монетизации pt.2 Запись занятия Разбор домашнего задания Воронка платежей", " Метрики монетизации pt.2 Запись занятия Разбор домашнего задания level 2 (HNTR) Постройте график накопительной конверсии с разбивкой по источнику пользователей. library(data.table) library(plotly) # импортируем данные installs &lt;- fread(&#39;https://gitlab.com/hse_mar/mar211f/-/raw/main/data/installs.csv&#39;) payments &lt;- fread(&#39;https://gitlab.com/hse_mar/mar211f/-/raw/main/data/payments_custom.csv&#39;) # перекодируем медиасорсы installs[is.na(media_source), media_source := &#39;organic&#39;] installs[media_source == &#39;other&#39;, media_source := &#39;organic&#39;] # выбираем первый инсталл installs &lt;- installs[order(user_pseudo_id, dt)] installs &lt;- installs[, .SD[1], by = user_pseudo_id] # берем платежи только новых пользователей payments_new &lt;- payments[user_pseudo_id %in% installs[, unique(user_pseudo_id)]] # прикрепляем к ним медиасорсы payments_new &lt;- merge( payments_new, installs[, list(user_pseudo_id, dt, media_source)], by = &#39;user_pseudo_id&#39;, all.x = TRUE ) # payments_new &lt;- merge( # payments_new, # installs[, list(user_pseudo_id, dt, media_source)], # by = &#39;user_pseudo_id&#39;, all = FALSE # ) # вычисляем лайфтайм payments_new[, lifetime := pay_dt - dt] # корректируем на окно лайфтайма # as.Date(&#39;2022-07-31&#39;) - as.Date(&#39;2022-06-30&#39;) payments_new &lt;- payments_new[dt &lt; &#39;2022-07-01&#39;] payments_new &lt;- payments_new[lifetime &lt;= 30] payments_new &lt;- payments_new[lifetime &gt;= 0] # считаем, когда пользователь сделал первый платеж (минимальный лайфтайм) payments_new_stat &lt;- payments_new[, list(lifetime = min(lifetime)), by = list(user_pseudo_id, media_source)] # считаем распределение пользователей по этому мин.лайфтайму payments_new_stat &lt;- payments_new_stat[, list(new_payer = uniqueN(user_pseudo_id)), by = list(media_source, lifetime)] # сортируем и делаем кумулятивную сумму payments_new_stat &lt;- payments_new_stat[order(media_source, lifetime)] payments_new_stat[, new_payer_cum := cumsum(new_payer), by = media_source] # считаем, сколько всего пользователей пришло installs_stat &lt;- installs[, list(total_users = uniqueN(user_pseudo_id)), by = media_source] payments_new_stat &lt;- merge( payments_new_stat, installs_stat, by = &#39;media_source&#39;, all.x = TRUE ) payments_new_stat[, conversion := new_payer_cum / total_users] # рисуем plot_ly(payments_new_stat, x = ~lifetime, y = ~conversion, color = ~media_source, type = &#39;scatter&#39;, mode = &#39;lines&#39;) %&gt;% layout( title = &#39;накопительная конверсия по источникам трафика&#39;, yaxis = list(rangemode = &#39;tozero&#39;) ) %&gt;% config(displayModeBar = FALSE) level 3 (HMP) Посчитайте по каждой платформе конверсию в платящих в день инсталла. Когорта – пришедшие в июне. Делать аналогично динамике ретеншена первого дня. # аналогично предыдущему заданию # пересобираем датасет, так как в прошлом задании мы в нем делали другие вычисления # и он нужен заново payments_new &lt;- payments[user_pseudo_id %in% installs[, unique(user_pseudo_id)]] payments_new &lt;- merge( payments_new, installs[, list(user_pseudo_id, dt, media_source)], by = &#39;user_pseudo_id&#39;, all.x = TRUE ) payments_new[, lifetime := pay_dt - dt] payments_new &lt;- payments_new[dt &lt; &#39;2022-07-25&#39;] payments_new &lt;- payments_new[lifetime &lt;= 7] payments_new &lt;- payments_new[lifetime &gt;= 0] # отличие от предыдущего задания -- делаем группировку не по медиасорсам, а по дате инсталла payments_new_stat &lt;- payments_new[, list(lifetime = min(lifetime)), by = list(user_pseudo_id, dt)] payments_new_stat &lt;- payments_new_stat[, list(new_payer = uniqueN(user_pseudo_id)), by = list(dt, lifetime)] installs_stat &lt;- installs[, list(total_users = uniqueN(user_pseudo_id)), by = dt] payments_new_stat &lt;- merge( payments_new_stat, installs_stat, by = &#39;dt&#39;, all.x = TRUE ) payments_new_stat &lt;- payments_new_stat[order(dt, lifetime)] payments_new_stat[, new_payer_cum := cumsum(new_payer), by = dt] payments_new_stat[, conversion := new_payer_cum / total_users] # оставляем только накопительную конверсию в платящих на определенные дни от инсталла payments_new_stat &lt;- payments_new_stat[lifetime %in% c(0, 1, 3, 7)] plot_ly(payments_new_stat[dt &lt; &#39;2022-07-01&#39;], x = ~dt, y = ~conversion, color = ~as.character(lifetime), type = &#39;scatter&#39;, mode = &#39;lines&#39;) %&gt;% layout( title = &#39;Динамика конверсии пользователей по дням&#39;, yaxis = list(rangemode = &#39;tozero&#39;) ) %&gt;% config(displayModeBar = FALSE) Воронка платежей Доля пользователей, которые сделали второй, третий и т.д. платеж. # опять пересобираем исходную табличку платежей payments_new &lt;- payments[user_pseudo_id %in% installs[, unique(user_pseudo_id)]] payments_new &lt;- merge( payments_new, installs[, list(user_pseudo_id, dt, media_source)], by = &#39;user_pseudo_id&#39;, all.x = TRUE ) # отсортировать платежи пользователей по возрастанию payments_new &lt;- payments_new[order(user_pseudo_id, ts)] # альтернативные методы сортировки # setkey(payments_new, user_pseudo_id, ts) # setorder(payments_new, user_pseudo_id, ts) # создаем номер платежа каждого пользователя. 1:.N -- и так в группе по пользователям payments_new[, purchase_number := 1:.N, by = user_pseudo_id] # payments_new[, purchase_number := seq(1, .N, by = 1), by = user_pseudo_id] payments_new[, lifetime := pay_dt - dt] payments_new &lt;- payments_new[dt &lt; &#39;2022-07-01&#39;] payments_new &lt;- payments_new[lifetime &lt;= 30] payments_new &lt;- payments_new[lifetime &gt;= 0] # считаем, сколько пользователей сделало платеж с этим номером payments_funnel &lt;- payments_new[, list(n_users = uniqueN(user_pseudo_id)), keyby = purchase_number] # считаем посчитать долю от всего пользователей, сделавших платеж (purchase_number == 1) payments_funnel[, total_payers := n_users[purchase_number == 1]] # если у нас есть группировка, то надо отдельно считать и мерджить по ключу # рисуем payments_funnel[, share := n_users / total_payers] plot_ly(payments_funnel[purchase_number &lt;= 10], x = ~purchase_number, y = ~share, type = &#39;bar&#39;) %&gt;% layout( title = &#39;Воронка платежей&#39; ) %&gt;% config(displayModeBar = FALSE) Воронки можно считать не от первого шага, а от предыдущего. В некоторых случаях это удобнее и информативнее. # если хотим считать от предыдущего шага payments_funnel[, prev_users := shift(n_users, n = 1)] payments_funnel[, prev_share := n_users / prev_users] plot_ly(payments_funnel[purchase_number &lt;= 10], x = ~purchase_number, y = ~prev_share, type = &#39;bar&#39;) %&gt;% layout( title = &#39;Воронка платежей, доля от предыдущего&#39; ) %&gt;% config(displayModeBar = FALSE) ## Warning: Ignoring 1 observations plot_ly(payments_funnel[purchase_number &lt;= 10], x = ~purchase_number, y = ~share, type = &#39;bar&#39;, name = &#39;% from payers&#39;) %&gt;% add_trace(y = ~prev_share, name = &#39;% from prev&#39;) %&gt;% layout( title = &#39;Воронка платежей&#39; ) %&gt;% config(displayModeBar = FALSE) ## Warning: Ignoring 1 observations "],["метрики-монетизации-pt.html", "Метрики монетизации pt.3 Запись занятия ARPU / ARPPU LTV Полезные материалы", " Метрики монетизации pt.3 Запись занятия ARPU / ARPPU Averange revenue per user - сумма платежей за определенный период, деленная на общее количество пользователей когорты. Средний чек, наверное, одна из самых важных метрик для оперирования продуктом, так как изучение структуры ARPU позволяет понять, за что платят пользователи и как можно улучшить эту метрику и так далее. Average revenue per paying user - сумма платежей за определенный период, деленная на количество платящих пользователей когорты. Обе метрики считаются в определенном окне (количестве дней от инсталла) - обычно 7, 28 или 30 дней. Это необходимо для того, чтобы учесть ситуацию, когда пользователи одной когорты (месячной, например) могли прожить разное количество дней в приложении. Или когда необходимо сравнить разные каналы привлечения, рекламные кампании или группы аб-тестов. задача 1 Считаем статистики в окне 7 дней от инсталла: library(data.table) library(plotly) library(kableExtra) # импортируем данные installs &lt;- fread(&#39;https://gitlab.com/hse_mar/mar211f/-/raw/main/data/installs.csv&#39;) payments &lt;- fread(&#39;https://gitlab.com/hse_mar/mar211f/-/raw/main/data/payments_custom.csv&#39;) # перекодируем медиасорсы installs[is.na(media_source), media_source := &#39;organic&#39;] installs[media_source == &#39;other&#39;, media_source := &#39;organic&#39;] # выбираем первый инсталл installs &lt;- installs[order(user_pseudo_id, dt)] installs &lt;- installs[, .SD[1], by = user_pseudo_id] # берем платежи только новых пользователей payments_new &lt;- payments[user_pseudo_id %in% installs[, unique(user_pseudo_id)]] # прикрепляем к ним медиасорсы payments_new &lt;- merge( payments_new, installs[, list(user_pseudo_id, dt, media_source)], by = &#39;user_pseudo_id&#39;, all.x = TRUE ) # вычисляем лайфтайм payments_new[, lifetime := pay_dt - dt] # корректируем на окно лайфтайма payments_new &lt;- payments_new[dt &lt; &#39;2022-07-01&#39;] payments_new &lt;- payments_new[lifetime &lt; 7] # отсюда надо считать количество денег и платящих # по сути, просто группировка по медиасорсу payments_new_stat &lt;- payments_new[, list( payers_7 = uniqueN(user_pseudo_id), gross_7 = sum(gross), n_purchases = .N ), by = media_source] # считаем, сколько всего пользователей пришло installs_stat &lt;- installs[, list(total_users = uniqueN(user_pseudo_id)), by = media_source] payments_new_stat &lt;- merge( installs_stat, payments_new_stat, by = &#39;media_source&#39;, all.x = TRUE ) payments_new_stat[, ARPU_7 := round(gross_7 / total_users, 2)] payments_new_stat[, ARPPU_7 := round(gross_7 / payers_7, 2)] payments_new_stat[, conv_7 := round(payers_7 / total_users, 3)] payments_new_stat[, avg_purchase := round(gross_7 / n_purchases, 1)] payments_new_stat[, purchases_per_user := round(n_purchases / payers_7, 1)] payments_new_stat ## media_source total_users payers_7 gross_7 n_purchases ARPU_7 ARPPU_7 ## 1: Facebook Ads 1297 40 612.47 64 0.47 15.31 ## 2: applovin_int 36818 878 17352.16 2161 0.47 19.76 ## 3: googleadwords_int 7774 122 2092.53 247 0.27 17.15 ## 4: organic 57690 753 16699.53 1968 0.29 22.18 ## 5: unityads_int 22017 206 2990.22 477 0.14 14.52 ## conv_7 avg_purchase purchases_per_user ## 1: 0.031 9.6 1.6 ## 2: 0.024 8.0 2.5 ## 3: 0.016 8.5 2.0 ## 4: 0.013 8.5 2.6 ## 5: 0.009 6.3 2.3 # kable_classic(kbl(payments_new_stat)) # kable_material(kbl(payments_new_stat)) LTV Lifetime value - общая сумма платежей, которые сделает пользователь за всю свою жизнь в приложении. Так как для каждого пользователя обычно сложно предсказать, сколько он проживет, то считается как кумулятивный средний чек когорты - общая накопленная сумма платежей, сделанная к определенному дню от инсталла, деленная на количество пользователей когорты. Кривая LTV/cumARPU сходится к общему значению ARPU по всей выборке за все время жизни когорты. LTV, фактически, одна из ключевых метрик, так как график LTV/cumARPU позволяет оценить динамику платежей когорты, сделать какие-то предсказания. Отношение LTV и CPI позволяют оценить эффективность рекламных кампаний. Например, за 90 дней от инсталла платежами пользователей возвращается 40-60% затраченных на привлечение денег. На 270-360 - все затраченные, и дальнейшие платежи составляют чистую прибыль (абстрактный пример, в реальности периоды сильно зависят от продукта). Соответственно, если даже в перспективе значение LTV когорты (сколько заплатит каждый привлеченный пользователь) не превысит CPI (сколько стоило привлечение каждого пользователя) когорты, то такая рекламная кампания убыточна и может быть полезна только для увеличение объема пользователей. задача 2 Посчитать кумулятивное ARPU 30 дня по июньской когорте Алгоритм - посчитать сумму гросса по дням лайфтайма - посчитать кумулятивную сумму этого гросса c помощью cumsum() - поделить кумулятивную сумму на общее количество пользователей когорты - нарисовать график # пересоздаем датасет, так как раньше отрезали только 7 дней # берем платежи только новых пользователей payments_new &lt;- payments[user_pseudo_id %in% installs[, unique(user_pseudo_id)]] # прикрепляем к ним медиасорсы payments_new &lt;- merge( payments_new, installs[, list(user_pseudo_id, dt, media_source)], by = &#39;user_pseudo_id&#39;, all.x = TRUE ) # вычисляем лайфтайм payments_new[, lifetime := pay_dt - dt] # корректируем на окно лайфтайма payments_new &lt;- payments_new[dt &lt; &#39;2022-07-01&#39;] payments_new &lt;- payments_new[lifetime &lt;= 30] payments_new &lt;- payments_new[lifetime &gt;= 0] # считаем платежи payments_new_stat &lt;- payments_new[, list(gross = sum(gross)), by = list(media_source, lifetime)] # сортируем и делаем кумулятивную сумму payments_new_stat &lt;- payments_new_stat[order(media_source, lifetime)] payments_new_stat[, gross_cum := cumsum(gross), by = media_source] # считаем, сколько всего пользователей пришло installs_stat &lt;- installs[, list(total_users = uniqueN(user_pseudo_id)), by = media_source] payments_new_stat &lt;- merge( payments_new_stat, installs_stat, by = &#39;media_source&#39;, all.x = TRUE ) payments_new_stat[, cumARPU := gross_cum / total_users] # рисуем plot_ly(payments_new_stat, x = ~lifetime, y = ~cumARPU, color = ~media_source, type = &#39;scatter&#39;, mode = &#39;lines&#39;) %&gt;% layout( title = &#39;cARPU по источникам трафика&#39;, yaxis = list(rangemode = &#39;tozero&#39;) ) %&gt;% config(displayModeBar = FALSE) Полезные материалы What Is a Business Model? 30 Successful Types of Business Models You Need to Know Коротко, что такое бизнес-модели, рассматриваются 30 разных моделей. Полезно для понимания, как вообще могут зарабатывать разные продукты. Основные метрики мобильных приложений Очень обзорный материал от devtodev. Есть неплохой блок по метрикам монетизации. "],["unit-экономика.html", "Unit-экономика Запись занятия Unit-экономика Дополнительные материалы", " Unit-экономика Запись занятия Unit-экономика Что это и зачем Юнит-экономика – определение числа юнитов масштабирования, маржинальная прибыль от которых необходима для покрытия постоянных издержек и выхода на заданный уровень прибыли. Основная идея юнит-экономики простая: Прибыль = маржинальная прибыль – постоянные расходы. Главное, как формируется маржинальная прибыль – количество клиентов, расходы на привлечение и удержание, Юнит-экономику можно считать как до запуска нового предприятия, так и после. Например, если мы хотим запустить стартап, то расписанная юнит-экономика стартапа нужна инвесторам, чтобы понимать за счет чего и когда будут окупаться вложения, насколько вообще жизнеспособна идея. Точно также юнит-экономику можно считать в уже существующем бизнесе, чтобы определить возможные зоны роста и слабые места. Стоит помнить, что расписанная юнит-экономика проекта — это всего лишь модель. А реализуют ее люди, и многие вещи будут зависеть не от модели или рынка, а от команды проекта. Юниты масштабирования Юнитом масштабирования может быть что угодно – одна сделка, одна продажа, один заказчик или подписчик. Юниты принято выбирать в соответствии с целями компании: что конкретно мы собираемся масштабировать. Юниты могут иметь разную иерархию, на примере пиццерии: заказ &gt; клиент &gt; пиццерия &gt; город &gt; страна. Точно также в рамках одной (крупной) компании может быть несколько разных юнитов. Сложностью юнита масштабирования добавляет новые метрики в формулы окупаемости и, в целом, рычагов ее изменеяия. Например, если мы продаем какой-то физический предмет, то нас интересует в первую очередь себестоимость товара. Если наш юнит – клиент, то мы смотрим на LTV и в модель закладываются расходы на удержание клиента, на повышение среднего чека, и т.д. Продуктовые аналитики обычно работают с проектами, где юнит масштабирования – клиент, именно поэтому наши ключевые метрики – ARPU, LTV, конверсия в платеж, среднее количество платежей на пользователя и т.д. Основные термины Fix Costs (Фиксированные расходы): расходы, не зависящие линейно от объема продаж или производства. Например, зарплата генерального директора или программиста в продуктовой компании. Variable Costs (Переменные расходы): расходы, непосредственно привязанные к единице товара или услуги. Например, стоимость сырья или доставка. В моделях обычно раскладывается на расходы на привлечение / маркетинг, удержание пользователя (Aquisition costs), себестоимость товара или услуги (COGS) и т.д. COGS (Cost of Goods Sold): Себестоимость единицы товара или услуги — стоимость материалов, логистики, оплата работы. В общем виде — переменные издержки, которые несет бизнес в момент сделки. Наивное правило, с помощью которого можно определить, относятся те или иные расходы к COGS или нет: если ваши расходы равны нулю, если у вас нет сделок, то это COGS, и наоборот – если не равны нулю (например, аренда или заработная плата), то это не COGS. First sale COGS (1sCOGS, Начальные расходы): Дополнительные переменные издержки, которые несет бизнес в момент самой первой сделки. Сюда же можно отнести расходы на первом этапе запуска проекта (закупка оборудования, пуско-наладочные работы и т. д.). Gross Profit (Валовая прибыль): разница между ценой товара или услуги и её себестоимостью. Нередко называют просто маржой. Если мы считаем не абсолютные значения (деньги), а долю от выручки, то это маржинальность, Gross Profit Margin. User/Unit (Пользователь): базовая сущность, определяет, с чем мы работаем, в общем случае представляет собой человека, который познакомился с продуктом благодаря рекламе. User / Lead Acqusition: количество привлекаемых пользователей. По сути горизонт масштабирования, если юнит масштабирования — пользователи. Aquisition costs (AC, Расходы на привлечение пользователей): расходы на рекламу, маркетинг, промокоды и другие сопутствующие расходы, на препродажи (если есть). AC = User Acquisition × Cost per Acquisition = Buyer × Customer Acquisition Cost CAC (Customer Acquisition Cost, Стоимость привлечения пользователя): расходы на привлечение одного платящего пользователя. То есть пользователя, который купил товар или услугу. Cost per Acquisition (CPA, Расходы на привлечение пользователя): стоимость привлечения пользователя, независимо, сделал он платеж или нет. В наиболее общем виде — стоимость маркетинговых затрат на юнит масштабирования. Наиболее характерные метрики: Cost per Install (CPI), Cost per Action (CPS), Cost per Lead (CPL). Сюда же можно отнести промежуточные метрики рекламных кампаний: Cost per Mile (CPM, цена за тысячу показов рекламы), CPC (Cost per Click, цена за количество кликов по рекламе) и прочие. Conversion to first purchase (C1, Конверсия в первую покупку): какой процент привлеченных юнитов масштабирования становится клиентами. Одна из ключевых метрик продукта, определяет, насколько хорошо продукт продает ценность. Buyer/Customer (B, клиент / пользователь): число клиентов, которых компания получает от потока пользователей с учетом имеющегося коэффициента конверсии. то есть это тот user / unit, который сделал покупку или воспользовался услугой. B = UA × C1. Average Payment Count (APC): Среднее число платежей, приходящееся на одного клиента. APC = Количество платежей / Buyer. Правда, надо учитывать интервал, за который сделаны платежи. Average Order Value (AOV или Av. Price, Средний чек): сумма, которую в среднем платят клиенты за товары или услуги. Customer Lifetime Value (CLTV): доход на одного платящего пользователя (клиента). Нюанс в том, что мы обычно не знаем, за какой период берутся платежи пользователя. Максимальный период – Lifetime, но в практике обычно берут 90/180/350 и более дней, в зависимости от бизнеса. CLTV = (Av. Price – COGS) × APC – 1sCOGS Contribution Margin (CM, Маржинальная прибыль): разница между тем, сколько мы получили от продажи товаров/услуг привлеченным пользователям и стоимостью привлечения пользователей. Можно выразть как Gross Profit - Acquisition Cost. Для достижения точки безубыточности маржинальная прибыль должна покрывать постоянные издержки. При положительном значении маржинальной прибыли говорят, что юнит-экономика сходится. А положительную разницу между маржинальной прибылью и постоянными издержками можно принять за EBITDA. Пример Общая идея бизнеса: покупаем стулья в Китае, привозим в Россию и продаем дистрибьютору. Предположим, продаем мы один стул за 1000 рублей (Av. Price). При этом наши переменные расходы (COGS) на единицу товара: 60 рублей налог (6% с оборота) 250 рублей закупка 100 рублей растаможка 150 рублей логистика 100 рублей брак (вероятность 10%) 40 рублей остальное Рекламы у нас нет, так как мы продаем стулья дистрибьютору. Поэтому Acquisition cost = 0. В результате с каждого стула у нас маржа (Gross Profit) 300 рублей. При этом мы не учитываем постоянные расходы на зарплату и аренду офиса/склада. Таким образом за 100 стульев мы получим 30000 рублей. Если вычесть постоянные расходы, то, скорее всего, мы будем в убытке. Однако если мы решим привезти 10000 стульев, то маржа вырастет, а переменные расходы останутся теми же. И мы, возможно, выйдем в прибыль. Шаблоны расчета Рекомендую поизучать шаблоны расчета юнит-экономики Ильи Красинского. Это один евангелистов юнит-экономики в ру-сегменте. У него достаточно подробный набор метрик, как общих, так и на пользователя. Точно также есть другие шаблоны, тысячи их: Шаблон юнит-экономики Яндекс Практикум Шаблон расчета юнит экономики (Skillbox) Симулятор стартапа Unit-экономика для аналитиков Юнит-экономика – в первую очередь инструмент для оценки бизнеса, поиска его узких точек и возможностей масштабирования. Продуктовые аналитики касаются только небольшой ее части — в первую очередь того, что касается поведения пользователя (то, как он платит, за что платит, как долго пользуется, как возвращается, как удерживается и т. д.), во вторую очередь — затраты на привлечение пользователя. И то в общем виде, сколько потратили на привлечение, так как более тонкими деталями типа CTR, IR, спецификой каналов привлечения, маркетинговой атрибуцией и т. д. занимаются больше маркетинговые аналитики. Постоянный расходы типа оплаты аренды офиса, ФОТ, налоги, прочие расходы и доходы, не связанные конкретно с клиентами/пользователями обычно остаются не в фокусе или вообще за пределами задач продуктовых аналитиков. Собственно, задача продуктовых аналитиков — тем или иным способом увеличить деньги от пользователя и таким образом повысить маржинальную прибыль и/или окупаемость. Дополнительные материалы учебник Д.Ханина по юнит-экономике. видео-курс Д.Ханина по юнит-экономике платный курс А.Горного “Unit-экономика от А до Я” конспект по юнит-экономике от Я.Практикума неплохая инфографика по юнит-экономике неплохая статья в блоке Контур.Компас "],["homework-1.html", "Homework 1 Общие замечания Описание данных Задание 1 Задание 2 Задание 3 Задание 4", " Homework 1 Общие замечания Срок сдачи работы: 26 ноября 2023 включительно. Домашнее задание лучше выполнять в R или R + Rmarkdown. Если R и Rmarkdown у вас вызывают сомнения, можете прислать решение в виде R скрипта, где комментарии по работе должны быть в виде строк комментариев. Если вы работаете в Python - аналогично, меня устроит и .ipynb, и .py. Если ни R, ни Python у вас не вызывают энтузиазма, и вы хотите как-то по-другому выполнять работу, напишите мне дополнительно. Свой файл с кодом решения назовите по структуре mar221_hw1_&lt;ваша фамилия латиницей&gt; и пришлите либо в личных сообщениях в slack, либо на почту upravitelev@gmail.com, в теме также укажите mar221_hw1_&lt;ваша фамилия латиницей&gt;. Старайтесь комментировать каждую значимую строчку кода (т. е., в которой происходит сложное или не очень прозрачное преобразование). Комментарии нужны, впервую очередь, для того, чтобы вы могли продемонстрировать, что понимаете, что и зачем делаете. Если некоторые операции однозначны и очевидны, комментарии можно опустить. Соблюдайте гайд по стилю оформления кода и/или используйте автоформатирование RStudio (ctr+shift+A на выделенном коде для Win/*nix). Отсутствие комментариев, неопрятность и/или нечитаемость кода, несоблюдение конвенций гайда по стилю - на все это я буду обращать внимание и, в случае существенных помарок, снижать оценку. Выполняйте задание самостоятельно. Если у меня возникнут затруднения в объективной оценке, то договоримся о созвоне и я попрошу прокомментировать то или иное решение, или же дам небольшое задание из аналогичных, чтобы сравнить стиль решения и рассуждений. Если при выполнении задания все же возникнут какие-то вопросы - можете спросить меня (все вопросы в слаке - либо в личке, либо в канале #random). Не гарантирую, что отвечу максимально подробно, но дать минимальную подсказку или прояснить неясность задания постараюсь. Имейте в виду, что данные сгенерированы (то есть, ненастоящие), поэтому в них могут быть артефакты или странности. тем, кто был на занятии по sql, настоятельно рекомендую джойны и фильтрации делать средствами SQL. Описание данных users.csv - инсталлы пользователей, с указанием даты инсталла, канала привлечения пользователя, стоимости привлечения (CPI) и версии приложения. auth.csv - даты авторизаций пользователей (в какие даты пользователи заходили в приложение). onboarding.csv - логи прохождение пользователями ключевых этапов от первого старта приложения до первой покупки (нередко этот этап или его часть называют онбордингом). payments.csv - логи платежей пользователей, содержат дату и размер платежа. NB! Считайте, что последний день, когда пользователи могли заходить в приложение - 21 ноября. Задание 1 Нарисуйте и проинтерпретируйте график удержания пользователей в приложении, с учетом канала привлечения пользователей. Попробуйте объяснить / предположить причины такой динамики метрики удержания в первые три дня (lifetime в интервале 0-2) по каналам. Рекомендация: на барчарте или в таблице видно лучше, чем на линейном графике. Напишите, каким образом можно было бы проверить вашу гипотезу. Задание 2 У вас есть приложение (маркетплейс), 16 октября приложение обновили с версии 0.3 до версии 0.4. Необходимо оценить результаты обновления. Описание приложения, точек монетизации и изменений в версии дано ниже. Данные после 1 ноября – артефакт, на них можно не обращать внимание. Описание приложения Маркетплейс (ozon, беру, avito, юла, joom, aliexpress, ebay и подобные). Приложение бесплатно для покупателей, вся выручка идет с продавцов. Продавцы платят: долю от каждой продажи (безлимитное количество объявлений) или фиксированную плату за какое-то количество объявлений за использование некоторых инструментов, по выбору продавца: промоутинг объявления в топе выдачи на какое-то время (если купить, то при релевантном запросе объявление этого продавца на какое-то время будет в выдаче выше аналогичных объявлений других продавцов) за страховку сделки маркетплейсом (деньги на счету покупателя блокируются до получения товара) за возможность указать телефон в профиле продавца индивидуальное оформление объявлений (фон, рамка, эмодзи) Changelog (изменения в функционале и исправления ошибок): сделали отдельный интерфейс для телефонов и планшетов (различия в ориентации, расположении некоторых кнопок и проч) подключили курьерскую службу и точки доставки (доставкой занимается маркетплейс, а не продавец) добавили шаблоны объявлений для наиболее популярных товаров включили сортировку объявлений по дате последнего изменения поменяли систему для техподдержки (был сервис Zendesk, стал Helpshift) починили редкий баг в автосохранении черновиков объявлений добавили звонки/голосовую связь между пользователями размер приложения увеличился на 70Мб и составил 130Мб Задание Покажите на графике, как изменилась прибыль проекта после запуска новой версии (если сможете, отметьте вертикальной линией на графике дату выхода новой версии). Поэкспериментируйте, какой тип графика будет тут удобнее для восприятия. Проведите исследование и объясните причины такой динамики (подкрепите выводы графиками или таблицами). Также сформулируйте гипотезы, что из продуктовых изменений могло привести к таким эффектами. Данные после 1 ноября – артефакт, на них можно не обращать внимание и не включать в интепретацию. На графике можно их скрыть. Задание 3 Посчитайте основные монетизационные метрики (количество платящих, конверсию, прибыль, ARPU, ARPPU, средний чек и среднее количество платежей, средний CPI), представьте в виде таблицы. В идеале должно получится четыре строчки в таблице: на каждый канал и одна общая. По возможности, округляйте дроби до значимых знаков после запятой (3 для конверсии и arpu/arppu, 1 для среднего чека или ср.количества платежей и т.д.). Нарисуйте график LTV по каналам привлечения пользователей. Проинтерпретируйте график LTV, оцените перспективу окупаемости пользователей с разных рекламных площадок. Дайте рекомендации маркетингу и специалистам по закупке трафика. Задание 4 Нарисуйте воронку шагов онбординга (первый событий пользователя в приложении) по версиям. Сделайте выводы, сформулируйте рекомендации для команды разработки. Информация о новых особенностях версии 0.4 дана выше в задании 2. Смысл шагов: st01_appstart - запуск приложения st02_sdk - инициализация sdk Facebook, Appsflyer st03_authorization - получение с сервера данных о профиле пользователя st04_download - дозагрузка дополнительных материалов st05_main_window - отрисовка основного окна приложения (завершение процесса старта) st06_oboarding_start - начало онбординга (как работать с приложением) st07_oboarding_end - завершение онбординга st08_add_adv - пользователь добавил самостоятельно объявление st9_purchase - пользователь сделал платеж "],["ux.html", "UX intro Запись занятия Полезные ссылки", " UX intro Запись занятия Полезные ссылки Телеграм-сообщество UX REsearch. Регулярная подборка лучших постов про UX-исследования и смежных областей. Конференция ПрофсоUX у них есть записи предыдущих конференций. Недавняя конференция UXlab Mail.ru. Много кейсов, выступают исследователи UX-лаборатории. Канал о личном опыте маркетинговых и продуктовых исследований: нетривиальных случаях, труднодоступных аудиториях и работающих методах. Customer Development и Custdev. Что это такое и в чем разница? Статья в блоге Олега Якубенкова. "],["sql.html", "SQL Запись занятия DBeaver Параметры подключений SQL r connectors Полезные ссылки", " SQL Запись занятия DBeaver https://dbeaver.io/download/ Параметры подключений user = “student” password = “pmsar2018” dbname = “pmsar” host = “188.225.77.95” port = 5432 SQL main structure SQL - декларативный язык с жестко закрепленным порядком операторов (зарезервированных ключевых слов) в sql-выражении. При запросе данных из таблицы обязательны select и from, остальные - по необходимости. select (указание, какие колонки таблицы должны быть в результате, аналог j в data.table- dt[i, j, by]) from (из какой таблицы или результата слияния таблиц должны быть выбраны колонки) join (какая таблица должна быть присоединена по ключу, аналог merge в R) where (набор логических выражений для фильтрация по строкам, аналогично фильтрации в data.table в разделе i - dt[i, j, by]) group by (по значениям каких колонок должна быть группировка, аналог by в data.table - dt[i, j, by]) order by (по значениям каких колонок должна быть отсортированная результирующая таблица) limit (ограничение на выдачу, сколько строк таблицы должно быть отдано) ; (завершение запроса, некоторые IDE могут за пользователя подставлять) simple query Простейшие арифметические запросы требуют select и все: select 1 + 5; Table 1: 1 records ?column? 6 select now(); Table 2: 1 records now 2023-11-26 18:56:27 select: columns selection Запросы для выбора колонок. * используется как аналог select all, то есть выбор всех колонок, которые есть в таблице. В разделе from указывается схема (набор таблиц) и таблица из этой схемы, через точку: public.chars означает таблица chars из схемы public: select * from public.chars limit 3; Table 3: 3 records row.names name height mass hair_color skin_color eye_color birth_year gender url planet_name 1 Luke Skywalker 172 77 blond fair blue 19BBY male https://swapi.co/api/people/1/ Tatooine 2 C-3PO 167 75 n/a gold yellow 112BBY n/a https://swapi.co/api/people/2/ Tatooine 3 Darth Vader 202 136 none white yellow 41.9BBY male https://swapi.co/api/people/4/ Tatooine Также в блоке select можно указать одну или несколько колонок, результат арифметических операций над колонками. select name, height, planet_name from public.chars limit 3; Table 4: 3 records name height planet_name Luke Skywalker 172 Tatooine C-3PO 167 Tatooine Darth Vader 202 Tatooine Алиасы формы column_name as new_name используются для переименования колонок или результатов вычислений. select name as char_name, height, planet_name, height * 3 as height_mult from public.chars limit 3; Table 5: 3 records char_name height planet_name height_mult Luke Skywalker 172 Tatooine 516 C-3PO 167 Tatooine 501 Darth Vader 202 Tatooine 606 where: rows selection Для фильтрации по строкам используют набор логических выражений в разделе where. where planet_name = 'Coruscant' читается как все строки, в которых в колонке planet_name встречается значение Coruscant. Строковые значения и даты указыаются в одинарных кавычках, двойные кавычки только для названий колонок и схем. select name, height, planet_name from public.chars where planet_name = &#39;Coruscant&#39;; Table 6: 3 records name height planet_name Finis Valorum 170 Coruscant Adi Gallia 184 Coruscant Jocasta Nu 167 Coruscant Логические выражения можно сочетать через операторы and и or, они аналогичны логическим операторам &amp; и | в R. select name, height, planet_name from public.chars where planet_name = &#39;Coruscant&#39; or height &gt;= 170; Table 7: Displaying records 1 - 10 name height planet_name Luke Skywalker 172 Tatooine Darth Vader 202 Tatooine Owen Lars 178 Tatooine Biggs Darklighter 183 Tatooine Anakin Skywalker 188 Tatooine Cliegg Lars 183 Tatooine Boba Fett 183 Kamino Lama Su 229 Kamino Taun We 213 Kamino Poggle the Lesser 183 Geonosis Оператор in аналогичен оператору %in% в R. Отрицание производится как not in: select name, height, planet_name from public.chars where planet_name in (&#39;Coruscant&#39;, &#39;Alderaan&#39;); Table 8: 6 records name height planet_name Leia Organa 150 Alderaan Bail Prestor Organa 191 Alderaan Raymus Antilles 188 Alderaan Finis Valorum 170 Coruscant Adi Gallia 184 Coruscant Jocasta Nu 167 Coruscant Также есть инструментарий проверки на вхождение, аналог grepl() в R. Для этого используется оператор like, а в качестве искомого выражения указывается строка, где % используются в качестве любые символы. Выражение planet_name like '%Coru%' можно прочитать как “все строки таблицы, в которых в колонке planet_name встречаются строковые значения, содержащие ‘Coru’, притом и до, и после ‘Coru’ могут быть еще символы”“. Отрицание также делается как not like, для регулярных выражений используется оператор ~: select name, height, planet_name from public.chars where planet_name like &#39;%Coru%&#39; or planet_name ~ &#39;raan&#39;; Table 9: 6 records name height planet_name Leia Organa 150 Alderaan Bail Prestor Organa 191 Alderaan Raymus Antilles 188 Alderaan Finis Valorum 170 Coruscant Adi Gallia 184 Coruscant Jocasta Nu 167 Coruscant group by: aggregations Группировки аналогичны группировкам в data.table - для каждой группы строк, выделяемых по значениям группирующей колонки, над колонками производятся вычисления (средние, суммы и проч). В примере ниже считается количество строк в таблице персонажей для каждого значения, количество уникальных персонажей (в таблице одна строка на персонажа, так что совпадает с предыдущим значением) и максимальный рост среди персонажей этой группы (всех персонажей с этой планеты): select planet_name, count(*) as n_rows, count(distinct name) as n_unique_chars, max(height) as max_height from public.chars group by planet_name limit 10; Table 10: Displaying records 1 - 10 planet_name n_rows n_unique_chars max_height Alderaan 3 3 191 Aleen Minor 1 1 79 Bespin 1 1 175 Bestine IV 1 1 180 Cato Neimoidia 1 1 191 Cerea 1 1 198 Champala 1 1 196 Chandrila 1 1 150 Concord Dawn 1 1 183 Corellia 2 2 180 join Слияние таблиц по ключу, в R аналогом выступает merge(). В зависимости от схемы присоединения, используются разные операторы джойна, чайще сего - left join (сохраняем все значения ключевой колонки в той таблице, к которой присоединяем) и inner join (сохраняем только те строки, по которым значения есть и в той таблице, к которой присоединяем, и в которой присоединяем). При этом в блоке select указываем те колонки, которые хотим получить из результата слияния. Если в таблицах используются одни и те же назания колонок, то колонки надо указывать с указанием таблицы или алиаса таблицы - table1.column_name. В разделе from указывается таблица, к которой присоединяется вторая или следующие таблицы. По возможности это должна быть самая короткая таблица. Ключ, по которому соединяются колонки - using(column_name). В том случае, когда в разных таблицах колонка-ключ называется по-разному, можно использовать выражение on table1.column_name1 = table2.column_name2. Где table1 и table2 - назания таблиц и могут быть заменены алиасами таблиц. В редких случаях в конструкции с on можно использовать знаки сравнения, чтобы фильтровать определенные значения, это может ускорять выполнение запроса, но стилистически это лучше делать в разделе where. Если через join присоединяется несколько таблиц, то они присоединяются не последовательно, к результату предыдущего джойна, а к таблице, указанной в from - то есть, порядок джойнов значения не имеет. В том случае, если используется внутренний селект (в выражении join указывается не таблица, а подзапрос, с select, from и прочими атрибутами), то для таким образом полученной таблицы нужно указать алиас. select name, height, skin_color, climate, gravity, terrain, ch.url as char_url, pl.url as planet_url from public.chars as ch left join ( select * from public.planets limit 10) as pl using(planet_name) order by name limit 5; Table 11: 5 records name height skin_color climate gravity terrain char_url planet_url Ackbar 180 brown mottle NA NA NA https://swapi.co/api/people/27/ NA Adi Gallia 184 dark temperate 1 standard cityscape, mountains https://swapi.co/api/people/55/ https://swapi.co/api/planets/9/ Anakin Skywalker 188 fair NA NA NA https://swapi.co/api/people/11/ NA Ayla Secura 178 blue NA NA NA https://swapi.co/api/people/46/ NA Bail Prestor Organa 191 tan temperate 1 standard grasslands, mountains https://swapi.co/api/people/68/ https://swapi.co/api/planets/2/ Визуальная схема вариантов джойнов (для merge() тоже полезно, для понимания аргументов all.x, all.y) r connectors Для подключения из R используется пакет RPostgreSQL. С помощью функции dbConnect(), куда аоргументами передаются параметры подключения, создается объект-коннектор. library(RPostgreSQL) con &lt;- dbConnect(PostgreSQL(max.con = 100), user = &quot;student&quot;, password = &quot;pmsar2018&quot;, dbname = &quot;pmsar&quot;, host = &quot;188.225.77.95&quot;, port = 5432) Запросы же делаются с помощью функции dbGetQuery() (простая функция для селектов, есть также отдельные функции для операций над таблицами). Первый аргумент функции - объект-коннектор, второй - строковая запись запроса. Нередко удобнее строку запроса записывать в отдельный объект: query &lt;- &quot; select name, height, planet_name from public.chars limit 3 &quot; res &lt;- dbGetQuery(conn = con, statement = query) res ## name height planet_name ## 1 Luke Skywalker 172 Tatooine ## 2 C-3PO 167 Tatooine ## 3 Darth Vader 202 Tatooine Результат выполнения выражения - объект класса data.frame. То есть, его в дальнейшем желательно переконвертировать в data.table: class(res) ## [1] &quot;data.frame&quot; После завершения работы (в идеале-после каждого запроса) соединение с базой надо закрывать: dbDisconnect(con) ## [1] TRUE Подключение и просмотр БД из RStudio В последних версиях RStudio реализовано подключение к базам данных, просмотр таблиц и вызов чистых sql-запросов - аналогично DBeaver. Для этого необходимо установить пакет odbc и соответствующие драйверы подключений баз данных (подробнее см. здесь). Само создание подключения к PosgreSQL-базе данных выглядит аналогично подключению через пакет RPostgreSQL: con_odbc &lt;- DBI::dbConnect(odbc::odbc(), # sudo apt-get install odbc-postgresql Driver = &quot;PostgreSQL Unicode&quot;, Server = &quot;188.225.77.95&quot;, Database = &quot;pmsar&quot;, UID = &quot;student&quot;, PWD = &quot;pmsar2018&quot;, Port = 5432) При этом в окне Connections (обычно в верхней правой части полей RStudio, где в Environment перечислены объекты в рабочем пространстве) появляются подключение и схемы базы данных, к которой совершено подключение. Схемы - раскрывающиеся списки, при клике выводятся все таблицы схемы. После того, как в RStudio произведено подключение таким образом, можно писать запросы в отдельных скриптах - для этого необходимо создать скрипт с расширением sql (например, File &gt; New file &gt; SQL script), а в первой строчке указать подключение, и потом нажать Preview или Ctrl+Shift+Enter: Полезные ссылки Гайды хорошего оформления sql-кода. Им необязательно следовать дословно, но все же желательно принимать во внимание. ТАк или иначе, самое главное - код должен быть лаконичным, опрятным и читабельным для коллег. style guide - я предпочитаю такой гайд, хотя он во многом может вызывать нарекания. В частности, операторы многие пишут заглавными буквами, так как это повышает их видимость в коде. Также в этом гайде критикуется разное выравнивание ключевых слов и названий таблиц (чтобы формировался “коридор”). второй гайд, один из моих коллег старается ему следовать, например. Особенно осмысленно выглядит критика префиксов в названиях колонок. список онлайн-курсов по SQL на DataCamp. Курсов, может быть, больше чем надо для реальной работы, но пройти базовые вполне можно. русскоязычный сайт-соревнование по решению задачек на SQL, некоторые задачки могут быть достаточно хардкорны. еще один неплохой ресурс с задачками по PostgreSQL. На самом деле онлайн-учебников и курсов очень много. "],["sql-advanced.html", "SQL advanced Запись занятия Части SQL data types values subquery Common tables expressions select experiments Window functions explain", " SQL advanced Запись занятия Части SQL Data Definition Language Набор команд для работы с объектами базы данных. С помощью этих команд можно создать, удалить или изменить какой-нибудь объект: таблицу, схему, функцию и т. д. Как правило для этих команд требуются дополнительные права пользователей. CREATE – для создания объектов базы данных ALTER – для изменения объектов базы данных DROP – для удаления объектов базы данных Data Manipulation Language Набор команд для работы с данными - выбор данных (из таблицы или таблиц), добавление или изменение данных, удаление данных (обычно строк из таблицы, сама таблица при этом остается на месте - для ее удаления нужно сделать DROP TABLE). SELECT – выборка данных INSERT – добавляет новые данные UPDATE – изменяет существующие данные DELETE – удаляет данные Data Control Language Организация и контроль над доступом к базе данных. Например, службе дашборда надо выдать права на чтение данных. GRANT – предоставляет пользователю или группе разрешения на определённые операции с объектом REVOKE – отзывает выданные разрешения DENY – задаёт запрет, имеющий приоритет над разрешением Transaction Control Language Команды для работы с транзакциями (группами запросов, которые выполняются пакетно, чтобы не было неконсистетности в данных). Обычно аналитики с такими задачами не сталкиваются. BEGIN – служит для определения начала транзакции COMMIT – применяет транзакцию ROLLBACK – откатывает все изменения, сделанные в контексте текущей транзакции SAVEPOINT – устанавливает промежуточную точку сохранения внутри транзакции data types list В PostgreSQL (как и в других диалектах) есть большой набор разных типов данных, от стандартных (целые числа, с дробной частью, с плавающей точкой, строки, даты) до экзотических типа ip-адресов. Подробный список типов можно посмотреть вот здесь: 8. Data Types: 8.1. Numeric Types 8.2. Monetary Types 8.3. Character Types 8.4. Binary Data Types 8.5. Date/Time Types 8.6. Boolean Type 8.7. Enumerated Types 8.8. Geometric Types 8.9. Network Address Types 8.10. Bit String Types 8.11. Text Search Types 8.12. UUID Type 8.13. XML Type 8.14. JSON Types 8.15. Arrays 8.16. Composite Types 8.17. Range Types 8.18. Domain Types 8.19. Object Identifier Types 8.20. pg_lsn Type 8.21. Pseudo-Types Numeric types При работе с числовыми типами надо помнить о такой особенности, что целые числа и числа с дробью - это разные типы. И, например, при делении целого числа на целое SQL вернет также целое число (в R будет неявное преобращование типа): select 1 / 7, 7 / 3 Table 1: 1 records ?column? ?column? 0 2 Один из самых простых вариантов явного преобразования - умножить целое число с типом numeric (то есть, на 1.000): select 1 * 1.000 / 7 Table 2: 1 records ?column? 0.1428571 Character Types Строковые типы, такие же как и в других языках программирования. select &#39;abc&#39; Table 3: 1 records ?column? abc Из полезных функций - конкатенация (слияние строк, аналог paste0() в R) и изменение регистра. select &#39;a&#39; || &#39;b&#39;, upper(&#39;abc&#39;), lower(&#39;ABC&#39;) Table 4: 1 records ?column? upper lower ab ABC abc Для работы со строковыми данными есть большая группа функций, использующих регулярные выражения. Вообще, регулярные выражения - весьма часто встречающаяся в жизни аналитиков вещь и их стоит освоить. Date/Time Types Даты и время. Несмотря на то, что для для людей более читабельны даты и время в ISO-представлении (‘гггг-мм-дд чч:мм:сс’), лучше использовать unix-timestamp – представление даты в виде количества секнуд с 1970-01-01. Это представление проще, удобнее для хранения, не зависит от таймзоны пользователя и базы данных. --текущая дата select current_date Table 5: 1 records date 2023-11-26 Для преобразования даты в unix-timestamp используют функцию extract() с указанием, что извлекается epoch. select extract(epoch from current_date) Table 6: 1 records date_part 1700956800 Обратное преобразование с помощью to_timestamp(): select to_timestamp(1636156800) Table 7: 1 records to_timestamp 2021-11-06 03:00:00 Даты вычитать достаточно просто, date - date. Но если надо из даты вычесть количество дней / месяцев / лет (или другой интервал), то можно воспользоваться следующей конструкцией: select current_date - interval &#39;1&#39; day Table 8: 1 records ?column? 2023-11-25 type Conversion Для преобразования типов в Postgresql обычно используют ::, также есть более классическая и распространенная во всех диалектах функция cast(): select 1 * 1.000 / 7, 1 :: numeric / 7, cast(1 as numeric) / 7 Table 9: 1 records ?column? ?column? ?column? 0.1428571 0.1428571 0.1428571 values Иногда бывают ситуации, когда надо создать таблицу в запросе - для этого можно с помощью команды values вычислить набор строк, в которых заданы значения (количество значений в строках должно быть одинаковыми). Названия колонок в создаваемой таблице можно задать с помощью as tablename(col1_name, col2_name…), по количеству создаваемых колонок. select * from ( values (1, &#39;a&#39;, &#39;grp1&#39;), (2, &#39;b&#39;, &#39;grp1&#39;) ) as tbl(var1, var2, var3) Table 10: 2 records var1 var2 var3 1 a grp1 2 b grp1 subquery Нередко в запросах надо обратиться к подвыборке из другой таблицы. Например, это может быть как в разделе join: select * -- создаем и обращаемся к первой таблице from ( values (1, &#39;a&#39;, &#39;grp1&#39;), (2, &#39;b&#39;, &#39;grp1&#39;) ) as tbl(var1, var2, var3) -- создаем и джойним вторую таблицу left join ( select * from ( values (&#39;2021-11-06&#39;, &#39;grp1&#39;) ) as tb2(var4, var3) ) as t2 using(var3) Table 11: 2 records var3 var1 var2 var4 grp1 1 a 2021-11-06 grp1 2 b 2021-11-06 Более простой пример с уже существующими таблицами: select * from chars left join ( select planet_name, gravity from planets where climate = &#39;temperate&#39; ) as p using(planet_name) Table 12: Displaying records 1 - 10 planet_name row.names name height mass hair_color skin_color eye_color birth_year gender url gravity Tatooine 1 Luke Skywalker 172 77 blond fair blue 19BBY male https://swapi.co/api/people/1/ NA Tatooine 2 C-3PO 167 75 n/a gold yellow 112BBY n/a https://swapi.co/api/people/2/ NA Tatooine 3 Darth Vader 202 136 none white yellow 41.9BBY male https://swapi.co/api/people/4/ NA Tatooine 4 Owen Lars 178 120 brown, grey light blue 52BBY male https://swapi.co/api/people/6/ NA Tatooine 5 Beru Whitesun lars 165 75 brown light blue 47BBY female https://swapi.co/api/people/7/ NA Tatooine 6 R5-D4 97 32 n/a white, red red unknown n/a https://swapi.co/api/people/8/ NA Tatooine 7 Biggs Darklighter 183 84 black light brown 24BBY male https://swapi.co/api/people/9/ NA Tatooine 8 Anakin Skywalker 188 84 blond fair blue 41.9BBY male https://swapi.co/api/people/11/ NA Tatooine 9 Shmi Skywalker 163 NA black fair brown 72BBY female https://swapi.co/api/people/43/ NA Tatooine 10 Cliegg Lars 183 NA brown fair blue 82BBY male https://swapi.co/api/people/62/ NA Также вложенные запросы могут быть в блоке where: select * from chars where planet_name in ( select planet_name from planets where climate = &#39;temperate&#39; ) Table 13: Displaying records 1 - 10 row.names name height mass hair_color skin_color eye_color birth_year gender url planet_name 11 Boba Fett 183 78.2 black fair brown 31.5BBY male https://swapi.co/api/people/22/ Kamino 12 Lama Su 229 88.0 none grey black unknown male https://swapi.co/api/people/72/ Kamino 13 Taun We 213 NA none grey black unknown female https://swapi.co/api/people/73/ Kamino 19 Leia Organa 150 49.0 brown light brown 19BBY female https://swapi.co/api/people/5/ Alderaan 20 Bail Prestor Organa 191 NA black tan brown 67BBY male https://swapi.co/api/people/68/ Alderaan 21 Raymus Antilles 188 79.0 brown light brown unknown male https://swapi.co/api/people/81/ Alderaan 22 Obi-Wan Kenobi 182 77.0 auburn, white fair blue-gray 57BBY male https://swapi.co/api/people/10/ Stewjon 24 Han Solo 180 80.0 brown fair brown 29BBY male https://swapi.co/api/people/14/ Corellia 25 Wedge Antilles 170 77.0 brown fair hazel 21BBY male https://swapi.co/api/people/18/ Corellia 27 Jabba Desilijic Tiure 175 NA n/a green-tan, brown orange 600BBY hermaphrodite https://swapi.co/api/people/16/ Nal Hutta Common tables expressions Общие таблицы или “выражения с with” – крайне полезный инструмент, так как позволяет создавать в запросе временные таблицы (которые живут только во время запроса и нигде не созраняются) и обращаться к этим таблицам во время запроса. Для экспериментов удобно совмещать создание таблиц из заданных значений с помощью values и операции с этими таблицами с помощью with: -- указываем, что таблицы из запросов ниже будут временными и общими для всего запроса with -- создаем первую таблицу tmp1 as ( select * from ( values (1, &#39;a&#39;, &#39;grp1&#39;), (2, &#39;b&#39;, &#39;grp1&#39;) ) as tbl(var1, var2, var3) ), -- создаем вторую таблицу tmp2 as ( select * from ( values (&#39;2021-11-06&#39;, &#39;grp1&#39;) ) as tb2(var4, var3) ) --основная часть - пишем запрос к созданным таблицам select * from tmp1 left join tmp2 using(var3) Table 14: 2 records var3 var1 var2 var4 grp1 1 a 2021-11-06 grp1 2 b 2021-11-06 select experiments functions В блоке select можно использовать разные, временами сложные конструкции. Самое простое - какая-то операция с колонкой, например, вычисление среднего (для среднего в sql-диалектах используется функция avg()) или максимума. with tmp as ( select * from ( values (1, &#39;a&#39;, &#39;grp1&#39;), (2, &#39;b&#39;, &#39;grp1&#39;) ) as tbl(v1, v2, v3) ) select count(*) as n_rows, count(distinct v3) as n_groups, avg(v1) as v2_avg from tmp Table 15: 1 records n_rows n_groups v2_avg 2 1 1.5 case Немного более сложный, но очень полезный инструмент - оператор логического ветвления. В R это аналог switch или вложенных ifelse. with tmp as ( select * from ( values (1, &#39;a&#39;, &#39;grp1&#39;), (2, &#39;b&#39;, &#39;grp1&#39;), (3, NULL, &#39;grp1&#39;), (4, &#39;d&#39;, &#39;grp2&#39;), (5, &#39;e&#39;, &#39;grp2&#39;) ) as tbl(v1, v2, v3) ) select *, -- открываем логическое ветвление case -- первое условие when v1 &lt; 3 then &#39;g1&#39; -- второе условие when v1 = 3 then &#39;g2&#39; -- третье условие - &quot;все прочее&quot; else &#39;g3&#39; -- закрываем ветвление и указываем, как назвать колонку end as grp2 from tmp Table 16: 5 records v1 v2 v3 grp2 1 a grp1 g1 2 b grp1 g1 3 NA grp1 g2 4 d grp2 g3 5 e grp2 g3 filter Полезная, но достаточно малоизвестная конструкция - значения в колонках можно фильтровать по значениям других колонок. with tmp as ( select * from ( values (1, &#39;a&#39;, &#39;grp1&#39;), (2, &#39;b&#39;, &#39;grp1&#39;), (3, NULL, &#39;grp1&#39;), (4, &#39;d&#39;, &#39;grp2&#39;), (5, &#39;e&#39;, &#39;grp2&#39;) ) as tbl(v1, v2, v3) ) select -- считаем количество строк, в которых в v3 есть значение grp1 count(*) filter(where v3 = &#39;grp1&#39;), -- одновременно считаем количество значений в колонке v1, для которых в v3 есть значение grp2 count(v1) filter(where v3 = &#39;grp2&#39;) from tmp Table 17: 1 records count count 3 2 Window functions row_number() over () Select-запросы в SQL предназначены в первую очередь для извлечения подвыборок (из одной или нескольких таблиц, с определенным составом колонок). Поэтому какие-то более сложные операции бывает достаточно сложно сделать. Одними из таких операций являются действия с колонками, в которых учитываются значения колонки в предыдущих строках - например, кумулятивная сумма или сумма в определенном окне (количестве строк до текущей) и тому подобные. Такие операции делаются в SQL с помощью оконных функций, где под окном понимается определенный набор строк колонки, с которыми надо выполнить какие-то операции. Один из самых простых видов оконных функций - нумерация строк: with tmp as ( select * from ( values (1, &#39;a&#39;, &#39;grp1&#39;), (2, &#39;b&#39;, &#39;grp1&#39;), (3, NULL, &#39;grp1&#39;), (4, &#39;d&#39;, &#39;grp2&#39;), (5, &#39;e&#39;, &#39;grp2&#39;) ) as tbl(v1, v2, v3) ) select *, -- row_number() - функция определения номера, over() - определение окна. -- так как в over() ничего не указано, под окном понимаются все строки таблицы row_number() over() as counter from tmp Table 18: 5 records v1 v2 v3 counter 1 a grp1 1 2 b grp1 2 3 NA grp1 3 4 d grp2 4 5 e grp2 5 over (partition by) Оконные операции можно выполнять в группах по значениям какой-то колонки, так же при этом можно сортировать строки по другим колонкам: with tmp as ( select * from ( values (1, &#39;a&#39;, &#39;grp1&#39;), (2, &#39;b&#39;, &#39;grp1&#39;), (3, NULL, &#39;grp1&#39;), (4, &#39;d&#39;, &#39;grp2&#39;), (5, &#39;e&#39;, &#39;grp2&#39;) ) as tbl(v1, v2, v3) ) select *, -- указываем, что окно бьется на группы в зависимости от значений v3 row_number() over(partition by v3) as counter, -- указываем, что окно бьется на группы в зависимости от значений v3 -- и одновременно сортируем значения по убыванию в зависимости от колонки v1 row_number() over(partition by v3 order by v1 desc) as counter_rev from tmp order by v1 Table 19: 5 records v1 v2 v3 counter counter_rev 1 a grp1 1 3 2 b grp1 2 2 3 NA grp1 3 1 4 d grp2 1 2 5 e grp2 2 1 total sum Другой пример запроса с оконной функцией – считаем общую сумму по колонке по всей таблице и записываем ее в отдельную колонку (значение суммы одно, просто размножается по количеству строк). with tmp as ( select * from ( values (1, &#39;a&#39;, &#39;grp1&#39;), (2, &#39;b&#39;, &#39;grp1&#39;), (3, NULL, &#39;grp1&#39;), (4, &#39;d&#39;, &#39;grp2&#39;), (5, &#39;e&#39;, &#39;grp2&#39;) ) as tbl(v1, v2, v3) ) select *, -- считаем сумму v1 по всем строкам таблицы sum(v1) over() as total_sum from tmp Table 20: 5 records v1 v2 v3 total_sum 1 a grp1 15 2 b grp1 15 3 NA grp1 15 4 d grp2 15 5 e grp2 15 cumulative sum Более сложная конструкция для вычисления кумулятивной суммы. Здесь мы указываем, что хотим посчитать не просто сумму, а кумулятивную сумму. Кумулятивная сумма представляется как сумма всех значений колонки от начала и до текущей строки – окно, в котором считается сумма, с каждой строкой расширяется. Такое поведение задается аргументом range, в котором указывем границы (можно и другие границы указать): with tmp as ( select * from ( values (1, &#39;a&#39;, &#39;grp1&#39;), (2, &#39;b&#39;, &#39;grp1&#39;), (3, NULL, &#39;grp1&#39;), (4, &#39;d&#39;, &#39;grp2&#39;), (5, &#39;e&#39;, &#39;grp2&#39;) ) as tbl(v1, v2, v3) ) select *, -- для каждой строки считаем сумму v1 от начала до текущей строки sum(v1) over(order by v1 range between unbounded preceding and current row) as cum_sum from tmp Table 21: 5 records v1 v2 v3 cum_sum 1 a grp1 1 2 b grp1 3 3 NA grp1 6 4 d grp2 10 5 e grp2 15 explain plan Для оптимизации можно посмотреть план запроса, который составляет оптимизатор. Умение читать и интерпретировать подобные планы приходит с опытом, чем больше - тем лучше, я не настолько хорошо знаю эту область, чтобы полноценно про нее рассказывать. Здесь просто для иллюстрации, что такое вообще есть. explain select * from chars where planet_name = &#39;Naboo&#39; Table 22: 2 records QUERY PLAN Seq Scan on chars (cost=0.00..2.96 rows=11 width=94) Filter: (planet_name = ‘Naboo’::text) analyze Когда мы явно указываем analyze, оптимизатор не просто создает план запроса, а реально выполняет запрос и выводит, сколько времени потребовалось выполнение того или иного этапа запроса. explain analyze select * from chars where planet_name = &#39;Naboo&#39; Table 23: 5 records QUERY PLAN Seq Scan on chars (cost=0.00..2.96 rows=11 width=94) (actual time=0.022..0.024 rows=11 loops=1) Filter: (planet_name = ‘Naboo’::text) Rows Removed by Filter: 66 Planning time: 0.060 ms Execution time: 0.047 ms "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
